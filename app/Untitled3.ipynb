{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5302522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd1ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "#import org.apache.spark.SparkConf\n",
    "#from pyspark.streaming.kafka import KafkaUtils\n",
    "#from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import from_json, col, explode, split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4c1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,org.apache.kafka:kafka-clients:3.3.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b03c814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325a4f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"twitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17d293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsraw = spark \\\n",
    "                   .readStream \\\n",
    "                   .format(\"kafka\") \\\n",
    "                   .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "                   .option(\"subscribe\", \"tweets\") \\\n",
    "                   .option(\"startingOffsets\", \"latest\") \\\n",
    "                   .load()\n",
    "dsraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9eeee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "ds = dsraw.selectExpr(\"CAST(value AS STRING)\")\n",
    "print(type(dsraw))\n",
    "print(type(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51b1cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawQuery = dsraw \\\n",
    "        .writeStream \\\n",
    "        .queryName(\"qraw\")\\\n",
    "        .format(\"memory\")\\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d95df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "alertQuery = ds \\\n",
    "        .writeStream \\\n",
    "        .queryName(\"qalerts\")\\\n",
    "        .format(\"memory\")\\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5d12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "|key|value|topic|partition|offset|timestamp|timestampType|\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from qraw\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cae219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Schema of a tweet coming from Twitter.\n",
    "\n",
    "tweet_schema=\"\"\"\n",
    "created_at string,\n",
    "id bigint,\n",
    "id_str string,\n",
    "text string,\n",
    "source string,\n",
    "truncated boolean,\n",
    "in_reply_to_status_id bigint,\n",
    "in_reply_to_status_id_str string,\n",
    "in_reply_to_user_id bigint,\n",
    "in_reply_to_user_id_str string,\n",
    "in_reply_to_screen_name string,\n",
    "`user` struct<\n",
    "            id:bigint,\n",
    "            id_str:string,\n",
    "            name:string,\n",
    "            screen_name:string,\n",
    "            location:string,\n",
    "            url:string,\n",
    "            description:string,\n",
    "            protected:boolean,\n",
    "            verified:boolean,\n",
    "            followers_count:bigint,\n",
    "            friends_count:bigint,\n",
    "            listed_count:bigint,\n",
    "            favourites_count:bigint,\n",
    "            statuses_count:bigint,\n",
    "            created_at:string,\n",
    "            profile_banner_url:string,\n",
    "            profile_image_url_https:string,\n",
    "            default_profile:boolean,\n",
    "            default_profile_image:boolean,\n",
    "            withheld_in_countries: array<string>,\n",
    "            withheld_scope:string,\n",
    "            geo_enabled:boolean\n",
    "            >,\n",
    "coordinates struct <\n",
    "            coordinates:array<float>,\n",
    "            type:string\n",
    "            >,\n",
    "place struct<\n",
    "            country:string,\n",
    "            country_code:string,\n",
    "            full_name:string,\n",
    "            place_type:string,\n",
    "            url:string\n",
    "            >,\n",
    "quoted_status_id bigint,\n",
    "quoted_status_id_str string,\n",
    "is_quote_status boolean,\n",
    "quote_count bigint,\n",
    "reply_count bigint,\n",
    "retweet_count bigint,\n",
    "favorite_count bigint,\n",
    "entities struct<\n",
    "            user_mentions:array<struct<screen_name:string>>,\n",
    "            hashtags:array<struct<text:string>>, \n",
    "            media:array<struct<expanded_url:string>>, \n",
    "            urls:array<struct<expanded_url:string>>, \n",
    "            symbols:array<struct<text:string>>\n",
    "            >,\n",
    "favorited boolean,\n",
    "retweeted boolean,\n",
    "possibly_sensitive boolean,\n",
    "filter_level string,\n",
    "lang string\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c047d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[event_time: string, screen_name: string, text: string, id: bigint]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. Cast the default data type of the field value (byte) to the String data type.\n",
    "# 3. Convert the String into a proper JSON document by using the from_json function.\n",
    "# 4. Flatten the JSON file and display event time, user name, text and the id.\n",
    "\n",
    "tweetsDF = dsraw.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "                      .select(from_json(col(\"value\"), tweet_schema).alias(\"data\")) \\\n",
    "                      .select(col(\"data.created_at\").alias(\"event_time\"), \n",
    "                              col(\"data.user.screen_name\"),\n",
    "                              col(\"data.text\"),\n",
    "                              col(\"data.id\"))\n",
    "tweetsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82c20449",
   "metadata": {},
   "outputs": [
    {
     "ename": "StreamingQueryException",
     "evalue": "Query [id = beb26f17-d4ff-4d74-b562-10ca5c9d662a, runId = 6db2d5c3-ee12-4517-9fc8-231a42c82cdc] terminated with exception: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStreamingQueryException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_880/277755410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 5. Display the results in the console.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtweetsDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteStream\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"console\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0moutputMode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"append\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\big-data\\spark3\\python\\pyspark\\sql\\streaming.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\big-data\\spark3\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\big-data\\spark3\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStreamingQueryException\u001b[0m: Query [id = beb26f17-d4ff-4d74-b562-10ca5c9d662a, runId = 6db2d5c3-ee12-4517-9fc8-231a42c82cdc] terminated with exception: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z"
     ]
    }
   ],
   "source": [
    "# 5. Display the results in the console.\n",
    "\n",
    "tweetsDF.writeStream \\\n",
    "        .format(\"console\") \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .start() \\\n",
    "     #   .awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a8259cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = false)\n",
      " |-- count: long (nullable = false)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe\n",
    "# NOTE on several methods employed here (hover over them for docs)\n",
    "words = dsraw.select(explode(split(dsraw.value, \" \")).alias(\"word\"))\n",
    "\n",
    "# Create word counter\n",
    "# NOTE: store in a new dataframe\n",
    "wordCounts = words.groupBy(\"word\").count()\n",
    "\n",
    "# * Print results\n",
    "print(wordCounts.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253897b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
